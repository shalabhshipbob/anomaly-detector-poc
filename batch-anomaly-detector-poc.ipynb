{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch anomaly detector POC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Anomaly Detector API's batch detection endpoint allows to detect anomalies through the entire times series data. In this detection mode, a single statistical model is created and applied to each point in the data set. If time series has the below characteristics, it is recommended to use batch detection to preview your data in one API call.\n",
    "\n",
    "* A seasonal time series, with occasional anomalies.\n",
    "* A flat trend time series, with occasional spikes/dips.\n",
    "\n",
    "Reference - https://docs.microsoft.com/en-us/azure/cognitive-services/anomaly-detector/concepts/anomaly-detection-best-practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To send requests to the Anomaly Detector API, we require anomaly detector access key and enpoint for the anomaly detector resource. These can be found in `Keys and Endpoint` menu item on left navigation bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apikey = '<Your api key>'\n",
    "endpoint = '<Your endpoint>'\n",
    "batch_detection_endpoint = f'{endpoint}/anomalydetector/v1.1-preview/timeseries/entire/detect'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps to run\n",
    "\n",
    "* Verify `apikey` and `endpoint` variables above have been updated with correct values.\n",
    "* Click on `Kernel` menu.\n",
    "* Click on `Restart & Run All` menu item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below is the function that'll make calls to Anomaly Detector API's batch detection endpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(endpoint, apikey, request_data):\n",
    "    headers = {'Content-Type': 'application/json', 'Ocp-Apim-Subscription-Key': apikey}\n",
    "    response = requests.post(endpoint, data=json.dumps(request_data), headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        return json.loads(response.content.decode(\"utf-8\"))\n",
    "    else:\n",
    "        print(response.status_code)\n",
    "        raise Exception(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below is the function that gets sample data from microsoft's github repo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_data():\n",
    "    url = 'http://raw.githubusercontent.com/Azure-Samples/AnomalyDetector/master/ipython-notebook/sample.json'\n",
    "    response = requests.get(url, verify=False)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "**Below is the code that fetches sample data and calls anomaly detector endpoint.**\n",
    "\n",
    "Anomaly detector endpoint returns anomaly information for each point in the sample data. Final output printed by this code is combined anomaly output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ignore the certifcate warning in the final output.\n",
    "\n",
    "data = get_sample_data()\n",
    "json_data = json.loads(data)\n",
    "json_data['sensitivity'] = 95\n",
    "\n",
    "result = detect(batch_detection_endpoint, apikey, json_data)\n",
    "combined_result = {\n",
    "    'granularity': json_data['granularity'],\n",
    "    'data': []\n",
    "}\n",
    "\n",
    "for index, point in enumerate(json_data['series']):\n",
    "    combined_result['data'].append({\n",
    "        'timestamp': point['timestamp'],\n",
    "        'value': point['value'],\n",
    "        'is_anomaly': result['isAnomaly'][index],\n",
    "        'is_negative_anomaly': result['isNegativeAnomaly'][index],\n",
    "        'is_positive_anomaly': result['isPositiveAnomaly'][index]\n",
    "    })\n",
    "\n",
    "print(json.dumps(combined_result, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
